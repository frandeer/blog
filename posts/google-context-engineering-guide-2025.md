# 구글이 공개한 70페이지 Context Engineering 가이드: AI가 당신을 기억하는 법

매일 아침 출근길에 들르는 카페를 상상해보세요. 3개월 정도 다니면 바리스타가 당신을 알아봅니다.

"오늘도 아이스 아메리카노 톨 사이즈, 시럽 빼고 드릴까요?"

이게 바로 **기억의 힘**입니다.

그런데 ChatGPT에게 똑같은 질문을 매일 하면 어떨까요? 매번 처음 만난 것처럼 "어떤 커피를 원하시나요?"라고 물어봅니다. 짜증나죠.

구글이 바로 이 문제를 해결하는 방법을 70페이지 백서로 공개했습니다. 그리고 저는 2시간 동안 읽고 핵심만 정리했습니다.

이제 AI도 당신의 단골 바리스타처럼 당신을 기억할 수 있습니다.

## 왜 AI는 건망증 환자처럼 행동할까?

현재 대부분의 AI 챗봇은 **상태를 저장하지 않습니다(stateless)**. 매번 대화를 새로 시작하는 거죠.

당신: "나 비건이야"
AI: "알겠습니다!"

*(다음날)*

당신: "점심 추천해줘"
AI: "삼겹살집 어때요?"

이런 경험 해보셨죠? AI가 똑똑해도 **기억력이 없으면** 쓸모없습니다.

반면 구글이 제시하는 **Context Engineering**을 적용하면:

- AI가 당신의 식습관을 기억합니다
- 당신의 코딩 스타일을 학습합니다
- 3개월 전 프로젝트도 맥락을 이해합니다
- 매번 같은 설명을 반복할 필요가 없습니다

이게 바로 **단순 기능(Feature)**과 **제대로 된 제품(Product)**의 차이입니다.

## Context Engineering이란 무엇인가?

간단하게 말하면: **AI에게 지금 필요한 정보만 딱 주는 기술**입니다.

LLM의 컨텍스트 윈도우는 한정적입니다. 마치 작업 책상 같아요. 책상이 넓어도 필요없는 책과 서류로 가득하면 일을 못하죠.

Context Engineering은 다음을 조합합니다:

1. **사용자 의도** - 지금 뭘 하려고 하는가?
2. **대화 기록** - 방금 전에 무슨 얘기를 했는가?
3. **검색된 지식** - RAG로 가져온 일반 정보
4. **장기 메모리** - 이 사용자에 대해 알고 있는 것
5. **실시간 데이터** - 도구 호출로 받은 최신 정보
6. **기반 데이터** - 대화를 고정하는 사실들

잘못된 Context Engineering: AI가 당신이 비건인 걸 기억 못하고 스테이크 집을 추천

훌륭한 Context Engineering: AI가 식단 제한, 선호 음식점, 동네, 음악 취향까지 기억하고 당신이 반복 설명 없이 완벽한 추천을 받음

## 구글이 제시하는 7가지 핵심 원칙

### 1. 세션은 작업대다

**세션(Session)**은 하나의 대화입니다. 명확한 시작과 끝이 있죠.

작업대를 여는 것과 닫는 것으로 생각하면 됩니다.

모든 세션은:
- **이벤트** - 사용자 메시지, AI 응답, 도구 호출, 관찰
- **상태** - 축적된 컨텍스트와 대화 기록
- **생명주기** - 시작, 상호작용, 종료

규칙: **하나의 작업, 하나의 세션**

- 코드 디버깅? 하나의 세션
- 휴가 계획? 새 세션
- 내일 다시 디버깅? 같은 세션을 이어가거나 새로 시작

여기서 핵심: **세션은 끝나지만 기억은 남습니다.**

세션이 닫혀도 학습한 내용은 보관됩니다. 이 분리 덕분에 AI는 **상태를 유지하면서도(기억하면서도)** 효율적입니다(무한한 짐을 끌고 다니지 않음).

### 2. 메모리는 파일 캐비닛이다

대부분 사람들이 **RAG와 메모리를 혼동**합니다. 완전히 다릅니다.

**RAG는 일반 지식을 검색합니다.** "프랑스 수도는?" → 파리. 누구에게나 동일.

**메모리는 당신만의 특성을 저장합니다.** "Sarah는 어떻게 디버깅하나?" "내 커피 주문은?" "내 리더십 스타일은?"

구글은 두 가지 메모리 유형을 사용합니다:

#### **선언적 메모리(Declarative Memory)** - 사실과 선호도

- "나는 비건이다"
- "TypeScript를 선호한다"
- "근무 시간은 오전 9시~오후 5시 EST"
- "땅콩 알레르기가 있다"

#### **절차적 메모리(Procedural Memory)** - 작업 방식

- "로그를 먼저 확인하며 디버깅한다"
- "회의를 잡담으로 시작한다"
- "설명보다 코드를 먼저 보여달라"
- "장단점 목록으로 결정한다"

이게 엄청나게 중요합니다.

선언적 = 정적 데이터. 절차적 = 동적 행동 패턴.

둘을 합치면 당신에 대해 **아는** AI가 아니라 당신과 **함께 일하는 방법을 아는** AI가 됩니다.

이는 사람들이 실제로 매일 사용하는 AI 제품을 만들 때 결정적입니다.

### 3. LLM이 스스로 기억을 생성한다

여기가 혁신입니다. **LLM이 메모리 생성을 스스로 주도합니다.**

자동화된 인텔리전스 추출입니다:

#### **1단계: 추출**

세션 중 LLM이 기억할 가치가 있는 정보를 식별합니다. 전부가 아니라 신호만.

*사용자: "모놀리스를 마이크로서비스로 마이그레이션 중. 개발자 200명 이상."*

추출: 회사 규모(200명 이상), 프로젝트(모놀리스→마이크로서비스), 컨텍스트(분산 시스템)

#### **2단계: 통합**

새 정보를 기존 메모리와 병합. 중복 제거. 업데이트. 신뢰도 개선.

- 이전: "사용자는 중견 기업에 있다"
- 새 정보: "200명 이상 개발자"
- 업데이트: "사용자는 대기업에 있다(200명 이상)"

#### **3단계: 로드**

정제된 메모리를 벡터 데이터베이스에 넣어 의미 기반 검색 가능하게.

이건 LLM 기반 ETL입니다. 데이터베이스 데이터를 옮기는 게 아니라 **대화 통찰을 지속적인 지식으로 결정화**하는 겁니다.

시스템이 매 상호작용마다 당신에 대해 학습합니다.

### 4. 출처는 신뢰 레이어다

프로덕션 시스템은 모든 메모리에 메타데이터가 필요합니다.

무엇을 기억하는지뿐 아니라 **어디서 왔는지, 얼마나 확실한지**.

**출처(Source)** - 어느 세션에서 생성?
*"2025-11-10 디버깅 세션에서 학습"*

**타임스탬프(Timestamp)** - 얼마나 최신?
*"3일 전 업데이트됨"*

**신뢰도(Confidence)** - 얼마나 확실?
*"높음(5회 이상 언급)" vs "낮음(한 번 언급, 농담일 수도)"*

출처는 디버깅 레이어입니다.

AI가 당신이 비건인데 잘못된 레스토랑을 제안?

메모리 출처 확인. 비건 선호도는 저장됐지만 신뢰도가 낮았음. 업데이트: 신뢰도 높이고, 검증 추가.

출처 없으면 메모리 시스템은 블랙박스.
출처 있으면 디버깅 가능, 신뢰 가능, 개선 가능.

이는 AI를 프로덕션으로 확장할 때 결정적입니다.

### 5. Push vs Pull 검색

모든 메모리가 모든 컨텍스트에 들어갈 필요는 없습니다.

스마트 시스템은 언제 푸시하고 언제 풀할지 압니다.

#### **능동 검색(Proactive Retrieval - Push)**

항상 포함. 협상 불가.

- 사용자 이름
- 안전 정보(알레르기)
- 핵심 선호도(언어, 시간대)
- 활성 프로젝트 컨텍스트

#### **반응 검색(Reactive Retrieval - Pull)**

의미 유사도로 필요시 검색.

- 과거 디버깅 패턴(디버깅 중일 때만)
- 과거 프로젝트 세부사항(관련 있을 때만)
- 절차적 지식(작업이 나올 때만)

균형이 전부입니다.

능동이 너무 많으면? 컨텍스트 공간 낭비, 모든 요청 느려짐.
능동이 너무 적으면? AI가 기억상실증.

구글의 방식: 필수 항목은 공격적으로 능동, 나머지는 지능적인 의미 검색.

AI가 실시간으로 이 쿼리에 어떤 과거 지식이 중요한지 결정합니다.

### 6. 프로덕션 현실은 냉혹하다

메모리가 있는 장난감 데모 만들기는 쉽습니다.

수백만 명에게 서비스하는 프로덕션 시스템? 여기서 팀들이 죽습니다.

#### **프라이버시**

사용자 데이터는 완전히 격리되어야 합니다. 당신의 메모리가 다른 사람 컨텍스트로 유출되면 절대 안 됩니다. 절대로.

이는 다음을 의미합니다:
- 엄격한 사용자 ID 경계
- 모든 곳에 암호화
- GDPR, CCPA 준수
- 사용자 제어(보기, 편집, 삭제)

#### **성능**

메모리 검색이 수 초의 지연을 추가하면 안 됩니다. 사용자는 즉각 반응을 기대합니다.

이를 위해 필요한 것:
- 공격적인 캐싱
- 배치 작업
- 효율적인 벡터 검색(SQL 아님)
- 스마트 프리페칭

#### **확장성**

수백만 사용자, 각각 수천 개의 메모리가 필요합니다.

구글의 인프라:
- 의미 검색용 벡터 데이터베이스
- 분산 메모리 스토어
- 지능적 만료 및 압축
- 우아한 성능 저하

이건 선택사항이 아닙니다. 프로덕션 AI의 기본입니다.

### 7. 컨텍스트 조립 오케스트레이션

모든 것이 여기서 합쳐집니다.

각 쿼리마다:

1. 의도 파싱
2. 메모리 검색(능동 + 반응)
3. 외부 지식 가져오기(RAG)
4. 실시간 데이터용 도구 호출
5. 최적 컨텍스트 조립
6. 완전한 인식으로 응답 생성
7. 새 메모리 추출

이게 밀리초 단위로 일어납니다. 매 쿼리마다.

오케스트레이션 레이어가 7가지 원칙을 모두 함께 작동하게 만듭니다.

## Context Rot: AI의 숨겨진 적

연구자들이 발견한 흥미로운 현상이 있습니다: **Context Rot(컨텍스트 부패)**.

"건초더미에서 바늘 찾기" 스타일 벤치마크 연구에서 밝혀진 것: 컨텍스트 윈도우의 토큰 수가 증가할수록 모델이 그 컨텍스트에서 정보를 정확히 기억하는 능력이 **감소**합니다.

마치 책상에 서류가 너무 많으면 정작 필요한 문서를 찾기 어려운 것과 같습니다.

Context Engineering이 이를 해결합니다:

- **압축(Compaction)**: 중요한 정보만 남기고 나머지 제거
- **요약(Summarization)**: 긴 대화 기록을 핵심만 추출
- **동적 큐레이션**: 실시간으로 기록을 정리하고 가지치기

GPT-3.5-turbo의 컨텍스트 윈도우는 4,096 토큰입니다. Gemini 1.5는 무려 100만 토큰으로 확장했죠.

하지만 크기가 중요한 게 아닙니다. **어떻게 관리하느냐**가 중요합니다.

## 실전 응용: 지금 당장 사용할 수 있는 곳

구체적으로 만들어봅시다.

### **코딩 어시스턴트**

- **세션** = 하나의 디버깅 작업 또는 기능
- **선언적 메모리** = 기술 스택, 코딩 선호도
- **절차적 메모리** = 디버깅 접근법, 패턴
- **능동** = 현재 프로젝트 컨텍스트, 활성 파일
- **반응** = 과거 버그, 과거 솔루션

### **글쓰기 어시스턴트**

- **세션** = 하나의 문서 또는 기사
- **선언적 메모리** = 주제, 독자, 톤
- **절차적 메모리** = 편집 스타일, 문구, 구조
- **능동** = 문서 컨텍스트, 스타일 가이드
- **반응** = 과거 기사, 연구 노트

### **개인 비서**

- **세션** = 하나의 작업(레스토랑 예약, 항공편 찾기, 일정 잡기)
- **선언적 메모리** = 선호도, 연락처, 캘린더
- **절차적 메모리** = 의사결정 패턴, 커뮤니케이션 스타일
- **능동** = 활성 캘린더, 즉각적인 선호도
- **반응** = 과거 선택, 과거 작업

패턴은 모든 도메인에 적용됩니다: 명확한 세션, 2단계 메모리, 지능적 검색, 지속적 학습.

## RAG와 메모리의 결정적 차이

많은 개발자들이 헷갈리는 부분입니다.

**RAG (Retrieval-Augmented Generation)**
- 오프라인에서 정보 저장
- 에이전트가 **읽기만** 가능
- 추론 중 쓰기/수정/삭제 불가
- 과거 상호작용에서 학습 불가 (기본값)

**Agent Memory**
- 추론 중 동적으로 업데이트
- 에이전트가 **읽고 쓰기** 가능
- 상호작용하며 계속 개선
- 시간이 지날수록 똑똑해짐

비유하자면:
- RAG = 도서관 (정보 검색만)
- Memory = 일기장 (계속 기록하고 참고)

최근 AI 커뮤니티에서는 "RAG가 죽었다"는 논쟁도 있지만, 사실은 **둘 다 필요**합니다. RAG와 장기 메모리를 통합하면 대규모 정보를 효율적으로 검색하고 처리하는 강력한 시스템이 됩니다.

## MemGPT: OS처럼 메모리 관리하기

**MemGPT(MemoryGPT)**는 흥미로운 접근법입니다.

운영체제가 RAM과 디스크를 관리하듯이, MemGPT는 메모리 계층을 구현합니다:

- **코어 메모리** (in-context) = RAM처럼 즉시 접근
- **아카이벌 메모리** (external) = 디스크처럼 장기 보관

에이전트가 필요에 따라 데이터를 이동시키며, 고정된 컨텍스트 제한 내에서 **무한 메모리의 환상**을 만듭니다.

마치 컴퓨터가 4GB RAM으로 100GB 작업을 하는 것처럼, AI도 작은 컨텍스트 윈도우로 거대한 대화 기록을 관리합니다.

## 실제 구현할 때 마주치는 어려운 문제들

구글의 프레임워크는 강력합니다. 하지만 구현에는 실제 도전과제가 있습니다.

### **도전 1: Cold Start (콜드 스타트)**

신규 사용자는 메모리가 없습니다. 아무것도 모르는 상태에서 어떻게 가치를 제공?

**구글의 접근:** 지능적 기본값 + 빠른 초기 학습 + 명시적 선호도 수집

처음 만났을 때 바리스타가 "어떤 커피 좋아하세요?" 물어보는 것처럼, AI도 처음엔 물어봐야 합니다.

### **도전 2: 메모리 충돌**

선호도가 바뀝니다. "나는 비건"이 "페스코테리안 시도 중"으로. 충돌을 어떻게 처리?

**해결책:** 타임스탬프 우선순위 + 신뢰도 점수 + 명시적 수정

최근 정보가 과거 정보를 덮어씁니다.

### **도전 3: 메모리 비대화**

사용자가 수천 개의 메모리를 생성합니다. 대부분은 대부분의 경우 관련 없음. 컨텍스트 오염을 어떻게 방지?

**해결책:** 메모리 만료 + 관련성 점수 + 공격적 압축

1년 전 커피 주문은 아마 더 이상 중요하지 않을 겁니다.

### **도전 4: 프라이버시 우려**

사용자들은 AI가 모든 걸 기억하는 것에 대해 정당하게 불안합니다. 메모리와 프라이버시의 균형은?

**해결책:** 투명성 + 사용자 제어 + 명확한 보관 + 내보내기/삭제 옵션

"내가 뭘 기억하고 있어?"를 언제든 볼 수 있어야 합니다.

## 다가오는 미래

구글이 이걸 재미로 공개한 게 아닙니다. 다음 세대 AI의 기반을 깔고 있습니다.

### **가까운 미래 (6-12개월)**

- 모든 주요 AI 제품에 메모리 탑재
- 사용자들이 AI가 자신을 기억하길 기대
- 메모리 없는 제품은 고장난 것처럼 느껴짐

### **중간 미래 (1-3년)**

- 당신의 작업 스타일을 진짜로 이해하는 AI 어시스턴트
- 몇 주에 걸친 멀티 세션 프로젝트 원활하게
- 사용할수록 똑똑해지는 개인 AI

### **먼 미래 (3-5년)**

- 인간보다 당신을 더 잘 아는 AI 동료
- 제품보다 오래 지속되는 디지털 메모리
- 플랫폼 간 이동 가능한 AI 메모리

Context Engineering이 이 모든 것의 기초입니다.

## 당신의 선택

AI 제품을 만들고 있다면 두 가지 선택이 있습니다:

**선택 1:** 무시하기. 사용자들이 신기함이 사라진 후 버리는 상태 없는 기능 계속 만들기.

**선택 2:** Context Engineering에 투자하기. 시간이 지날수록 가치가 복리로 쌓이는 AI 제품 만들기.

기술적 프레임워크는 더 이상 비밀이 아닙니다. 구글이 방금 공개했으니까요.

경쟁 우위는 **잘 구현하는 팀**에게 갑니다.

여기서 시작하세요:

1. RAG vs Fine-tuning 마스터하기
2. Prompt Engineering 탁월해지기
3. AI 에이전트 아키텍처 이해하기
4. Context Engineering 레이어 추가하기
5. 적절한 AI 평가 시스템 구축하기

경주는 누가 먼저 만드느냐가 아닙니다.

누가 **제대로** 만드느냐입니다.

구글이 수년간 알아낸 걸 70페이지 청사진으로 당신에게 건넸습니다.

질문은 이겁니다: 당신은 이걸로 뭘 만들 건가요?

---

## 핵심 요약

1. **Context Engineering**은 AI에게 필요한 정보를 필요한 때 정확히 제공하는 기술
2. **세션**은 작업의 단위, **메모리**는 세션을 넘어 지속되는 학습
3. **선언적 메모리**(사실)와 **절차적 메모리**(행동 패턴) 모두 필요
4. LLM이 스스로 대화에서 메모리를 추출하고 통합
5. **RAG는 일반 지식**, **메모리는 개인화된 학습** - 완전히 다름
6. 프로덕션에서는 프라이버시, 성능, 확장성이 필수
7. Context Rot을 방지하려면 압축과 큐레이션 필요

AI는 이제 **기억하는 법**을 배웠습니다.

당신의 제품은 준비됐나요?

---

## Sources

- [Google's Final Guide For Context Engineering](https://medium.com/coding-nexus/googles-final-guide-for-context-engineering-mastering-ai-agents-sessions-and-memory-in-2025-011fb28ca61d)
- [Beyond the Hype: A Technical Deep-Dive into Google's Context Engineering Architecture](https://medium.com/@shashwatabhattacharjee9/beyond-the-hype-a-technical-deep-dive-into-googles-context-engineering-architecture-2bb8ad00d203)
- [Context Engineering Guide - Prompt Engineering Guide](https://www.promptingguide.ai/guides/context-engineering-guide)
- [RAG is not Agent Memory - Letta](https://www.letta.com/blog/rag-vs-agent-memory)
- [The Evolution from RAG to Agentic RAG to Agent Memory](https://www.leoniemonigatti.com/blog/from-rag-to-agent-memory.html)
- [Understanding LLM Short-Term and Long-Term Memory](https://medium.com/@jennytan5522/understanding-large-language-model-llm-short-term-and-long-term-memory-fa1e2d56fc2b)
- [Context Engineering: Sessions, Memory](https://medium.com/@patmcc1979/context-engineering-sessions-memory-0505b825a273)
- [LLM Memory Systems - Cognee](https://www.cognee.ai/blog/fundamentals/llm-memory-cognitive-architectures-with-ai)
